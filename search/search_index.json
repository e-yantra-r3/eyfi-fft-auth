{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"FFT based Authentication System Abstract In this post-covid world everything is getting changed so we have to adopt to changes . Biometric based authentication is outdated now and its need of the hour to develop novel systems which can be helpful at corporate offices,malls,labs,colleges where authenticating systems are used .An alternative to biometric fingerprint or keypad pushbuttons .Make accessing places most hygienic while maintaining security with personalized virtual keys on mobile phones. Safe shared no-contact access with ultrasonic keys that are as easy as a voice text message. here we will be making two different kinds of authentication system We built ultrasonic authentication system using our eYFi- mega development board . We also interfaced the same with Google sheets to dynamically update the log in details and time stamps of unique users . We made use on very few components to complete this Authentication system. This system was tested for reliability,accuracy,dependability and lot of other factors. We have implemented both e-YFi mega based solution as well as Day to day Laptop based solution so we can retrofit this system anywhere within fraction of time . Cloud based support is given as well so that all the details can be monitored form anywhere Variants of our design e-YFi Mega based demo ( using Phone and ESp32-authenticating node) Python based demo ( using Phone and Laptop-authenticating node) DEMO OF OUR PROJECT How \u200dUltrasonic Access Control Works ? Ultrasonic keys are coded \u201csilent\u201d audio messages that are sent from a mobile phone app to any electronic entrance keypad. As a person holding a mobile phone nears the corresponding electronic entrance requiring the manual handling of a magnetic card, a biometric fingerprint or a push button keypad, the mobile plays an audio (ultrasonic) code that essentially is the virtual key. Because the message is in the form of sound waves, which are naturally confined within a specific location, the message itself confirms that the phone is right there at the access point. That natural quality, together with our tokenized security technology, transforms the message into a personalized, controlled key. Unlike a password or pass coded number an ultrasonic key is always virtual and can never be copied, lost or stolen; it will simply be deleted and replaced. Sending Data Over Sound: How and Why? Demand grows for better IoT connectivity, with the need for the most basic of smart devices to be able to process real-time audio and perform intelligent DSP. One emerging solution is sending data-over-sound. Thus, data-over-sound software works well in a situation where there\u2019s no network access, like rural or RF-restricted areas.\" From smartphones and tablets, to industrial equipment and smart-home appliances, hundreds of thousands of smart devices now require different forms of connectivity. The inevitable demand for better connectivity in the IoT era has increased the expectations for even the most basic smart devices to have the capability to process real-time audio and perform intelligent digital signal processing (DSP) on the network's entry point device. This has ultimately paved the way for a host of innovative market entrants, looking to both challenge and work in tandem with traditional solutions to provide quality data-transmission capabilities. Data-over-sound is one technology that\u2019s now rapidly emerging as an exciting connectivity option for engineers and developers looking to achieve frictionless interactions between an ever-growing number of connected devices. But how exactly does data-over-sound work let us see about it now . How Does it Work? In short, data-over-sound enables the exchange of data between any devices with a pre-existing loudspeaker or microphone through sound waves. Delivered through machine-to-machine communications software, the technology works like an audio QR code, sending data over an acoustic channel to enhance end-user experiences and add value to existing hardware. In practice, data is encoded into an acoustic signal\u2014a series of audible or inaudible pitches and tones to form a kind of sonic barcode. This is then played into a space and received and demodulated by a listening device. Data is subsequently decoded by the receiving device, or group of devices, and returns the original data. By using a range of audio frequencies, programmers can fit more information into less audio. To filter out noise, we carefully select frequencies and tune our software . Why Sound? Ultrasonic connectivity solves the major limitations of existing RF-based communication standards . It outstrips RF connectivity by providing: Low price and absolutely No special hardware needed. High security \u2013 Verifies physical presence in compliance with SCA and enables session verification out of band, preventing man-in-the-middle attacks. Total reliability \u2013 Always on, and works where WiFi, GSM, GPS, etc. cannot work or are unavailable. Improved safety \u2013 Zero electromagnetic radiation. Data-over-sound has a multitude of complementary capabilities when compared to other connectivity technologies. The technology\u2019s position as a pairing-free, one-to-many medium means it mitigates some of the setup and provisioning pain points often associated with traditional alternatives such as Bluetooth and Wi-Fi, presenting an appealing and versatile solution for frictionless data transmission. In general, compared to other technologies, data-over-sound is also able to be used in very wide application areas, taking advantage of existing hardware and without prior setup or configuration. Doing so, it enables the interconnection of millions of devices in a seamless, scalable, and cost-effective way to enhance end-user experience and drive value without increasing hardware costs. This ability to enhance existing infrastructure has inevitably captured the interest of companies interested in adding wireless connectivity functionality without adding to their bill of materials. The Benefits of Sending Data over Sound Embedding and extracting meaning from sound provides a quick, secure, and cost-effective solution that works completely offline. Data-over-sound is now emerging as an ideal medium for simple implementation and reliable connectivity. Some of the most clear affordances of sound include: Works offline : Sound works peer-to-peer or one-to-many, meaning no additional connections or network dependencies are needed . Thus, data-over-sound software works well in a situation where there\u2019s no network access, like rural or RF-restricted areas. Here every phone or device will have mic and speskers Utilize existing hardware: The rise of microphones in IoT devices means that the hardware requirements are already met for billions of existing devices of all form factors. Combined with the arrival of zero-power microphones, data-over-sound provides an extremely low power. This will be Eliminating the need for additional hardware saves users both money and resources that can be invested back into the business. Secure, private data transfer : Because acoustic connection doesn\u2019t require an internet connection and supports industry-standard cryptography, you\u2019ll have peace of mind that any data transferred will not be compromised. No audio, not even audio metadata, is ever stored or sent from a receiving device for processing. Supports range of platforms: Data-over-sound is compatible with machines and devices of different platforms, form factors, and architectures that can process audio. From smartphones and tablets to toys and games, and even legacy and analog equipment, any device with a microphone and speaker can receive and decode data with the technology. Seamless integration : Often implementing new software can be resource- and time-intensive. However, data-over-sound can be delivered through software-development kits (SDKs), which provides a fast and easy integration to a host of platform types, making the solution ideal for hobbyist developers and IoT projects. Scalable : With data-over-sound, there\u2019s no need to reengineer as your application grows. Whether the aim is to enable seamless P2P exchanges or send data from one-to-many, this method of data transfer is completely scalable. Use cases for data-over-sound are therefore wide ranging. They can include IoT devices sending and receiving commands, secure transactions, and un-spoofable receipts to merchants or buyers, as well as sending/receiving credentials (to provision Wi-Fi, for example). Works in extreme environments : Through a range of frequencies, data-over-sound software is robust to background noise and has been proven to work seamlessly in the most extreme environments. From the streets of Delhi to nuclear power stations, acoustic network connectivity remains universally strong in the toughest environments. Applications of using sound Ultrasonic Payments: Facilitating secure pairing for mobile payments and contactless ATM interaction , already SBI yoni has mobile based withdrawal , which will include mobile based passcode as well so if we just go there with our phone then we will get the cash without any physical interaction with the ATM machine . Ultrasonic Authentication: Providing a seamless and secure identification solution a fully developed app that can be easily integrated and used by any third party application .this can replace the present biometric authentication system,rfid etc. Challenges ahead we do have some form of challenges and problems which can definitely be solved with relevant methods Problem 1: Audio Hardware Limitations For our proposed solution, we need to broadcast the identifier (as ultrasonic sound) into an environment. We want this signal to be as strong as possible, but there are limits. An audio system can be overdriven which results in clipping. You\u2019ve heard clipping if you\u2019ve ever turned your speakers all the way up and the sound starts to get grainy. We see the same problem on the signal detection side. Microphones each have their own characteristic roll off, and will detect audible frequencies with greater ease than ultrasonic frequencies. And since the responsiveness characteristics of microphones vary depending on the frequencies to which they are exposed, we don\u2019t get the same magnitude measure for two different frequencies even if they are played at equal intensity. Finally, most speakers and microphones are responsive to the frequency range of 20 Hz to 20 kHz which is more than enough to account for the range of human hearing. However, this means that our usable bandwidth of ultrasonic frequencies is small. The number of frequencies we can produce/detect at one time is limited. Problem 2: Computation on Eyifi-Mega Development board The longer the amount of recorded audio, the greater precision we can achieve with frequency analysis. However, more recorded audio also requires greater processing time in the analysis phase, which is done on our development board. Many mobile devices simply lack the computational horsepower to simultaneously record audio, store it, and perform frequency analysis. We continue to tune the system so that we have a fast response time and high precision during the analysis phase. We\u2019ve found the system works best when we use 1024 samples of audio at 44100 samples per-second for each loop in the receiver. A power of two is necessary for the Fast Fourier Transform to function properly. As smartphones get better, we anticipate this being less and less of a problem. novel idea where we use the sound spectrum to communicate between two devices and authenticate one's identity . We are proposing a protocol for data connectivity and authentication over sound waves. This will also serve us as out-of-band M2M connectivity. We have encompassed a protocol which uniquely harnesses the power of Near ultrasound sound (17khz -20khz) to verify physical presence and authentication unprecedented precision. It is now possible to deliver a digital-like experience in the physical world \u2013 opening new opportunities for IoT, DSPs .","title":"Home"},{"location":"#abstract","text":"In this post-covid world everything is getting changed so we have to adopt to changes . Biometric based authentication is outdated now and its need of the hour to develop novel systems which can be helpful at corporate offices,malls,labs,colleges where authenticating systems are used .An alternative to biometric fingerprint or keypad pushbuttons .Make accessing places most hygienic while maintaining security with personalized virtual keys on mobile phones. Safe shared no-contact access with ultrasonic keys that are as easy as a voice text message. here we will be making two different kinds of authentication system We built ultrasonic authentication system using our eYFi- mega development board . We also interfaced the same with Google sheets to dynamically update the log in details and time stamps of unique users . We made use on very few components to complete this Authentication system. This system was tested for reliability,accuracy,dependability and lot of other factors. We have implemented both e-YFi mega based solution as well as Day to day Laptop based solution so we can retrofit this system anywhere within fraction of time . Cloud based support is given as well so that all the details can be monitored form anywhere","title":"Abstract"},{"location":"#variants-of-our-design","text":"e-YFi Mega based demo ( using Phone and ESp32-authenticating node) Python based demo ( using Phone and Laptop-authenticating node) DEMO OF OUR PROJECT","title":"Variants of our design"},{"location":"#how-ultrasonic-access-control-works","text":"Ultrasonic keys are coded \u201csilent\u201d audio messages that are sent from a mobile phone app to any electronic entrance keypad. As a person holding a mobile phone nears the corresponding electronic entrance requiring the manual handling of a magnetic card, a biometric fingerprint or a push button keypad, the mobile plays an audio (ultrasonic) code that essentially is the virtual key. Because the message is in the form of sound waves, which are naturally confined within a specific location, the message itself confirms that the phone is right there at the access point. That natural quality, together with our tokenized security technology, transforms the message into a personalized, controlled key. Unlike a password or pass coded number an ultrasonic key is always virtual and can never be copied, lost or stolen; it will simply be deleted and replaced.","title":"How \u200dUltrasonic Access Control Works ?"},{"location":"#sending-data-over-sound-how-and-why","text":"Demand grows for better IoT connectivity, with the need for the most basic of smart devices to be able to process real-time audio and perform intelligent DSP. One emerging solution is sending data-over-sound. Thus, data-over-sound software works well in a situation where there\u2019s no network access, like rural or RF-restricted areas.\" From smartphones and tablets, to industrial equipment and smart-home appliances, hundreds of thousands of smart devices now require different forms of connectivity. The inevitable demand for better connectivity in the IoT era has increased the expectations for even the most basic smart devices to have the capability to process real-time audio and perform intelligent digital signal processing (DSP) on the network's entry point device. This has ultimately paved the way for a host of innovative market entrants, looking to both challenge and work in tandem with traditional solutions to provide quality data-transmission capabilities. Data-over-sound is one technology that\u2019s now rapidly emerging as an exciting connectivity option for engineers and developers looking to achieve frictionless interactions between an ever-growing number of connected devices. But how exactly does data-over-sound work let us see about it now .","title":"Sending Data Over Sound: How and Why?"},{"location":"#how-does-it-work","text":"In short, data-over-sound enables the exchange of data between any devices with a pre-existing loudspeaker or microphone through sound waves. Delivered through machine-to-machine communications software, the technology works like an audio QR code, sending data over an acoustic channel to enhance end-user experiences and add value to existing hardware. In practice, data is encoded into an acoustic signal\u2014a series of audible or inaudible pitches and tones to form a kind of sonic barcode. This is then played into a space and received and demodulated by a listening device. Data is subsequently decoded by the receiving device, or group of devices, and returns the original data. By using a range of audio frequencies, programmers can fit more information into less audio. To filter out noise, we carefully select frequencies and tune our software .","title":"How Does it Work?"},{"location":"#why-sound","text":"Ultrasonic connectivity solves the major limitations of existing RF-based communication standards . It outstrips RF connectivity by providing: Low price and absolutely No special hardware needed. High security \u2013 Verifies physical presence in compliance with SCA and enables session verification out of band, preventing man-in-the-middle attacks. Total reliability \u2013 Always on, and works where WiFi, GSM, GPS, etc. cannot work or are unavailable. Improved safety \u2013 Zero electromagnetic radiation. Data-over-sound has a multitude of complementary capabilities when compared to other connectivity technologies. The technology\u2019s position as a pairing-free, one-to-many medium means it mitigates some of the setup and provisioning pain points often associated with traditional alternatives such as Bluetooth and Wi-Fi, presenting an appealing and versatile solution for frictionless data transmission. In general, compared to other technologies, data-over-sound is also able to be used in very wide application areas, taking advantage of existing hardware and without prior setup or configuration. Doing so, it enables the interconnection of millions of devices in a seamless, scalable, and cost-effective way to enhance end-user experience and drive value without increasing hardware costs. This ability to enhance existing infrastructure has inevitably captured the interest of companies interested in adding wireless connectivity functionality without adding to their bill of materials.","title":"Why Sound?"},{"location":"#the-benefits-of-sending-data-over-sound","text":"Embedding and extracting meaning from sound provides a quick, secure, and cost-effective solution that works completely offline. Data-over-sound is now emerging as an ideal medium for simple implementation and reliable connectivity. Some of the most clear affordances of sound include: Works offline : Sound works peer-to-peer or one-to-many, meaning no additional connections or network dependencies are needed . Thus, data-over-sound software works well in a situation where there\u2019s no network access, like rural or RF-restricted areas. Here every phone or device will have mic and speskers Utilize existing hardware: The rise of microphones in IoT devices means that the hardware requirements are already met for billions of existing devices of all form factors. Combined with the arrival of zero-power microphones, data-over-sound provides an extremely low power. This will be Eliminating the need for additional hardware saves users both money and resources that can be invested back into the business. Secure, private data transfer : Because acoustic connection doesn\u2019t require an internet connection and supports industry-standard cryptography, you\u2019ll have peace of mind that any data transferred will not be compromised. No audio, not even audio metadata, is ever stored or sent from a receiving device for processing. Supports range of platforms: Data-over-sound is compatible with machines and devices of different platforms, form factors, and architectures that can process audio. From smartphones and tablets to toys and games, and even legacy and analog equipment, any device with a microphone and speaker can receive and decode data with the technology. Seamless integration : Often implementing new software can be resource- and time-intensive. However, data-over-sound can be delivered through software-development kits (SDKs), which provides a fast and easy integration to a host of platform types, making the solution ideal for hobbyist developers and IoT projects. Scalable : With data-over-sound, there\u2019s no need to reengineer as your application grows. Whether the aim is to enable seamless P2P exchanges or send data from one-to-many, this method of data transfer is completely scalable. Use cases for data-over-sound are therefore wide ranging. They can include IoT devices sending and receiving commands, secure transactions, and un-spoofable receipts to merchants or buyers, as well as sending/receiving credentials (to provision Wi-Fi, for example). Works in extreme environments : Through a range of frequencies, data-over-sound software is robust to background noise and has been proven to work seamlessly in the most extreme environments. From the streets of Delhi to nuclear power stations, acoustic network connectivity remains universally strong in the toughest environments.","title":"The Benefits of Sending Data over Sound"},{"location":"#applications-of-using-sound","text":"Ultrasonic Payments: Facilitating secure pairing for mobile payments and contactless ATM interaction , already SBI yoni has mobile based withdrawal , which will include mobile based passcode as well so if we just go there with our phone then we will get the cash without any physical interaction with the ATM machine . Ultrasonic Authentication: Providing a seamless and secure identification solution a fully developed app that can be easily integrated and used by any third party application .this can replace the present biometric authentication system,rfid etc.","title":"Applications of using sound"},{"location":"#challenges-ahead","text":"we do have some form of challenges and problems which can definitely be solved with relevant methods Problem 1: Audio Hardware Limitations For our proposed solution, we need to broadcast the identifier (as ultrasonic sound) into an environment. We want this signal to be as strong as possible, but there are limits. An audio system can be overdriven which results in clipping. You\u2019ve heard clipping if you\u2019ve ever turned your speakers all the way up and the sound starts to get grainy. We see the same problem on the signal detection side. Microphones each have their own characteristic roll off, and will detect audible frequencies with greater ease than ultrasonic frequencies. And since the responsiveness characteristics of microphones vary depending on the frequencies to which they are exposed, we don\u2019t get the same magnitude measure for two different frequencies even if they are played at equal intensity. Finally, most speakers and microphones are responsive to the frequency range of 20 Hz to 20 kHz which is more than enough to account for the range of human hearing. However, this means that our usable bandwidth of ultrasonic frequencies is small. The number of frequencies we can produce/detect at one time is limited. Problem 2: Computation on Eyifi-Mega Development board The longer the amount of recorded audio, the greater precision we can achieve with frequency analysis. However, more recorded audio also requires greater processing time in the analysis phase, which is done on our development board. Many mobile devices simply lack the computational horsepower to simultaneously record audio, store it, and perform frequency analysis. We continue to tune the system so that we have a fast response time and high precision during the analysis phase. We\u2019ve found the system works best when we use 1024 samples of audio at 44100 samples per-second for each loop in the receiver. A power of two is necessary for the Fast Fourier Transform to function properly. As smartphones get better, we anticipate this being less and less of a problem. novel idea where we use the sound spectrum to communicate between two devices and authenticate one's identity . We are proposing a protocol for data connectivity and authentication over sound waves. This will also serve us as out-of-band M2M connectivity. We have encompassed a protocol which uniquely harnesses the power of Near ultrasound sound (17khz -20khz) to verify physical presence and authentication unprecedented precision. It is now possible to deliver a digital-like experience in the physical world \u2013 opening new opportunities for IoT, DSPs .","title":"Challenges ahead"},{"location":"#_1","text":"","title":""},{"location":"Firmware/","text":"eYFi -Mega Code We developed our code using Arduino IDE for eyantra . We have made use of lot of libraries for display,wifi client ,Http requests and certificates. Relevant comments are added in this code and this code was completely tested Go through the following code. Code for FFT authentication ( Near Ultrasonic) #include <Wire.h> #include <WiFi.h> #include <HTTPClient.h> #include \"arduinoFFT.h\" #include \"SSD1306.h\" #define SAMPLES 512 // Bin size for computing FFT #define SAMPLING_FREQUENCY 40000 //Our sampling frequency #define amplitude 100 SSD1306 display(0x3c,SDA,SCL); // This is to intiate the Display module attached arduinoFFT FFT = arduinoFFT(); //Create an object of FFT class for Computation unsigned int sampling_period_us; unsigned long microseconds; double vReal[SAMPLES]; //Real values of the plotted FFT double vImag[SAMPLES]; //Imaginary values of plotted FFT unsigned long newTime, oldTime; //For ADC converison and sampling purpose using this int aravinda=0; //Flag to authenticate only once ( 1 or 0) int sourav=0; const char * ssid = \"Ishavasyam WiFi\"; //Network credentials const char * password = \"ishavasyamidamsarvam216\"; //Network credentials String GOOGLE_SCRIPT_ID = \"AKfycbxR_zSZXTKHCSI4V2tCeCNpGgHTgp3dCH6AQcnQic7WmYv52Ak\"; // Id of the goole docs sheet which we are using to store const int sendInterval = 996 *5; // in millis, 996 instead of 1000 is adjustment, with 1000 it jumps ahead a minute every 3-4 hours const char * root_ca=\\ \"-----BEGIN CERTIFICATE-----\\n\" \\ \"MIIDujCCAqKgAwIBAgILBAAAAAABD4Ym5g0wDQYJKoZIhvcNAQEFBQAwTDEgMB4G\\n\" \\ \"A1UECxMXR2xvYmFsU2lnbiBSb290IENBIC0gUjIxEzARBgNVBAoTCkdsb2JhbFNp\\n\" \\ \"Z24xEzARBgNVBAMTCkdsb2JhbFNpZ24wHhcNMDYxMjE1MDgwMDAwWhcNMjExMjE1\\n\" \\ \"MDgwMDAwWjBMMSAwHgYDVQQLExdHbG9iYWxTaWduIFJvb3QgQ0EgLSBSMjETMBEG\\n\" \\ \"A1UEChMKR2xvYmFsU2lnbjETMBEGA1UEAxMKR2xvYmFsU2lnbjCCASIwDQYJKoZI\\n\" \\ \"hvcNAQEBBQADggEPADCCAQoCggEBAKbPJA6+Lm8omUVCxKs+IVSbC9N/hHD6ErPL\\n\" \\ \"v4dfxn+G07IwXNb9rfF73OX4YJYJkhD10FPe+3t+c4isUoh7SqbKSaZeqKeMWhG8\\n\" \\ \"eoLrvozps6yWJQeXSpkqBy+0Hne/ig+1AnwblrjFuTosvNYSuetZfeLQBoZfXklq\\n\" \\ \"tTleiDTsvHgMCJiEbKjNS7SgfQx5TfC4LcshytVsW33hoCmEofnTlEnLJGKRILzd\\n\" \\ \"C9XZzPnqJworc5HGnRusyMvo4KD0L5CLTfuwNhv2GXqF4G3yYROIXJ/gkwpRl4pa\\n\" \\ \"zq+r1feqCapgvdzZX99yqWATXgAByUr6P6TqBwMhAo6CygPCm48CAwEAAaOBnDCB\\n\" \\ \"mTAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUm+IH\\n\" \\ \"V2ccHsBqBt5ZtJot39wZhi4wNgYDVR0fBC8wLTAroCmgJ4YlaHR0cDovL2NybC5n\\n\" \\ \"bG9iYWxzaWduLm5ldC9yb290LXIyLmNybDAfBgNVHSMEGDAWgBSb4gdXZxwewGoG\\n\" \\ \"3lm0mi3f3BmGLjANBgkqhkiG9w0BAQUFAAOCAQEAmYFThxxol4aR7OBKuEQLq4Gs\\n\" \\ \"J0/WwbgcQ3izDJr86iw8bmEbTUsp9Z8FHSbBuOmDAGJFtqkIk7mpM0sYmsL4h4hO\\n\" \\ \"291xNBrBVNpGP+DTKqttVCL1OmLNIG+6KYnX3ZHu01yiPqFbQfXf5WRDLenVOavS\\n\" \\ \"ot+3i9DAgBkcRcAtjOj4LaR0VknFBbVPFd5uRHg5h6h+u/N5GJG79G+dwfCMNYxd\\n\" \\ \"AfvDbbnvRG15RjF+Cv6pgsH/76tuIMRQyV+dTZsXjAzlAcmgQWpzU/qlULRuJQ/7\\n\" \\ \"TBj0/VLZjmmx6BEP3ojY+x1J96relc8geMJgEtslQIxq/H5COEBkEveegeGTLg==\\n\" \\ \"-----END CERTIFICATE-----\\n\"; WiFiClientSecure client; void drawRectDemo() { // Draw a pixel at given position for (int i = 0; i < 10; i++) { display.setPixel(i, i); display.setPixel(10 - i, i); } display.drawRect(12, 12, 20, 20); // Fill the rectangle display.fillRect(14, 14, 17, 17); // Draw a line horizontally display.drawHorizontalLine(0, 40, 20); // Draw a line horizontally display.drawVerticalLine(40, 0, 20); } void drawSpectrum(int sig, int len_sig) { display.clear(); display.drawRect(0, 0, 128, 64); display.setFont(ArialMT_Plain_10); display.setTextAlignment(TEXT_ALIGN_CENTER); display.drawString(64, 2, \"EYANTRA LAB\"); } void setup() { Serial.begin(115200); Wire.begin(5,4); // SDA, SCL display.init(); display.setFont(ArialMT_Plain_10); display.flipScreenVertically(); // Adjust to suit or remove sampling_period_us = round(1000000 * (1.0 / SAMPLING_FREQUENCY)); WiFi.mode(WIFI_STA); WiFi.begin(ssid, password); while (WiFi.status() != WL_CONNECTED) { delay(500); Serial.print(\".\"); } } void loop() { display.clear(); drawSpectrum(0,0); display.display(); for (int i = 0; i < SAMPLES; i++) { newTime = micros()-oldTime; oldTime = newTime; vReal[i] = analogRead(A0); // A conversion takes about 1uS on an ESP32 vImag[i] = 0; while (micros() < (newTime + sampling_period_us)) { /* do nothing to wait */ } } //Selection of proper window technique to obtain optimum results FFT.Windowing(vReal, SAMPLES, FFT_WIN_TYP_BLACKMAN_HARRIS, FFT_FORWARD); //Computation of FFt algorithm to obtain Real and imaginary value FFT.Compute(vReal, vImag, SAMPLES, FFT_FORWARD); FFT.ComplexToMagnitude(vReal, vImag, SAMPLES); //Convert to mag int j=0; //$- But system for proof of concept ( max0-max3) int max0=0; int max1=0; int max2=0; int max3=0; //This can either be done by calibration or by formula from ( sampling,CHUNK,desired freq) for (int i = 150 ; i < 250; i++) // for loop to iterate via all bins { if (vReal[i]>150 && i>170 &&i <180) // this is 16khz { max1 = 1; } if (vReal[i]>150 && i>185 &&i <188) // this is 17khz { max1 = 1; } if (vReal[i]>50 && i>195 &&i <205) // this is 18khz { max2 = 1; } if (vReal[i]>100 && i>210 &&i <230) // this is 19.1khz { max3 = 1; } } //To cehck for bits and print relevant user detalils ( in future it might be used with firebase if( max0==0 && max1==1 && max2==0 && max3==0 && aravinda == 0 ) { Serial.println(\"ARAVINDA HARITHSA\"); display.setFont(ArialMT_Plain_10); display.setTextAlignment(TEXT_ALIGN_CENTER); display.drawString(64, 22, \"ARAVINDA HARITHSA\"); display.drawString(64, 32, \"AUTHENTICATED...\"); display.display(); delay(1000); display.clear(); HTTPClient http; String url=\"https://script.google.com/macros/s/\"+GOOGLE_SCRIPT_ID+\"/exec?\"+ \"info1=Aravinda&info2=Intern&temp=temp\"; http.begin(url, root_ca); int httpCode = http.GET(); Serial.println(\"DONE_\"); http.end(); aravinda =1; } if(max0==0 && max1==0 && max2==1 && max3==0 && sourav == 0 ) { Serial.println(\"SOURAV JENA\"); display.setFont(ArialMT_Plain_10); display.setTextAlignment(TEXT_ALIGN_CENTER); display.drawString(64, 22, \"SOURAV JENA\"); display.drawString(64, 32, \"AUTHENTICATED...\"); display.display(); HTTPClient http; String url=\"https://script.google.com/macros/s/\"+GOOGLE_SCRIPT_ID+\"/exec?\"+ \"info1=Souvrav_Jena&info2=Mentor&temp=Permanent\"; http.begin(url, root_ca); int httpCode = http.GET(); Serial.println(httpCode); http.end(); delay(1000); sourav = 1; }","title":"eYFi -Mega Code"},{"location":"Firmware/#eyfi-mega-code","text":"We developed our code using Arduino IDE for eyantra . We have made use of lot of libraries for display,wifi client ,Http requests and certificates. Relevant comments are added in this code and this code was completely tested Go through the following code.","title":"eYFi -Mega Code"},{"location":"Firmware/#code-for-fft-authentication-near-ultrasonic","text":"#include <Wire.h> #include <WiFi.h> #include <HTTPClient.h> #include \"arduinoFFT.h\" #include \"SSD1306.h\" #define SAMPLES 512 // Bin size for computing FFT #define SAMPLING_FREQUENCY 40000 //Our sampling frequency #define amplitude 100 SSD1306 display(0x3c,SDA,SCL); // This is to intiate the Display module attached arduinoFFT FFT = arduinoFFT(); //Create an object of FFT class for Computation unsigned int sampling_period_us; unsigned long microseconds; double vReal[SAMPLES]; //Real values of the plotted FFT double vImag[SAMPLES]; //Imaginary values of plotted FFT unsigned long newTime, oldTime; //For ADC converison and sampling purpose using this int aravinda=0; //Flag to authenticate only once ( 1 or 0) int sourav=0; const char * ssid = \"Ishavasyam WiFi\"; //Network credentials const char * password = \"ishavasyamidamsarvam216\"; //Network credentials String GOOGLE_SCRIPT_ID = \"AKfycbxR_zSZXTKHCSI4V2tCeCNpGgHTgp3dCH6AQcnQic7WmYv52Ak\"; // Id of the goole docs sheet which we are using to store const int sendInterval = 996 *5; // in millis, 996 instead of 1000 is adjustment, with 1000 it jumps ahead a minute every 3-4 hours const char * root_ca=\\ \"-----BEGIN CERTIFICATE-----\\n\" \\ \"MIIDujCCAqKgAwIBAgILBAAAAAABD4Ym5g0wDQYJKoZIhvcNAQEFBQAwTDEgMB4G\\n\" \\ \"A1UECxMXR2xvYmFsU2lnbiBSb290IENBIC0gUjIxEzARBgNVBAoTCkdsb2JhbFNp\\n\" \\ \"Z24xEzARBgNVBAMTCkdsb2JhbFNpZ24wHhcNMDYxMjE1MDgwMDAwWhcNMjExMjE1\\n\" \\ \"MDgwMDAwWjBMMSAwHgYDVQQLExdHbG9iYWxTaWduIFJvb3QgQ0EgLSBSMjETMBEG\\n\" \\ \"A1UEChMKR2xvYmFsU2lnbjETMBEGA1UEAxMKR2xvYmFsU2lnbjCCASIwDQYJKoZI\\n\" \\ \"hvcNAQEBBQADggEPADCCAQoCggEBAKbPJA6+Lm8omUVCxKs+IVSbC9N/hHD6ErPL\\n\" \\ \"v4dfxn+G07IwXNb9rfF73OX4YJYJkhD10FPe+3t+c4isUoh7SqbKSaZeqKeMWhG8\\n\" \\ \"eoLrvozps6yWJQeXSpkqBy+0Hne/ig+1AnwblrjFuTosvNYSuetZfeLQBoZfXklq\\n\" \\ \"tTleiDTsvHgMCJiEbKjNS7SgfQx5TfC4LcshytVsW33hoCmEofnTlEnLJGKRILzd\\n\" \\ \"C9XZzPnqJworc5HGnRusyMvo4KD0L5CLTfuwNhv2GXqF4G3yYROIXJ/gkwpRl4pa\\n\" \\ \"zq+r1feqCapgvdzZX99yqWATXgAByUr6P6TqBwMhAo6CygPCm48CAwEAAaOBnDCB\\n\" \\ \"mTAOBgNVHQ8BAf8EBAMCAQYwDwYDVR0TAQH/BAUwAwEB/zAdBgNVHQ4EFgQUm+IH\\n\" \\ \"V2ccHsBqBt5ZtJot39wZhi4wNgYDVR0fBC8wLTAroCmgJ4YlaHR0cDovL2NybC5n\\n\" \\ \"bG9iYWxzaWduLm5ldC9yb290LXIyLmNybDAfBgNVHSMEGDAWgBSb4gdXZxwewGoG\\n\" \\ \"3lm0mi3f3BmGLjANBgkqhkiG9w0BAQUFAAOCAQEAmYFThxxol4aR7OBKuEQLq4Gs\\n\" \\ \"J0/WwbgcQ3izDJr86iw8bmEbTUsp9Z8FHSbBuOmDAGJFtqkIk7mpM0sYmsL4h4hO\\n\" \\ \"291xNBrBVNpGP+DTKqttVCL1OmLNIG+6KYnX3ZHu01yiPqFbQfXf5WRDLenVOavS\\n\" \\ \"ot+3i9DAgBkcRcAtjOj4LaR0VknFBbVPFd5uRHg5h6h+u/N5GJG79G+dwfCMNYxd\\n\" \\ \"AfvDbbnvRG15RjF+Cv6pgsH/76tuIMRQyV+dTZsXjAzlAcmgQWpzU/qlULRuJQ/7\\n\" \\ \"TBj0/VLZjmmx6BEP3ojY+x1J96relc8geMJgEtslQIxq/H5COEBkEveegeGTLg==\\n\" \\ \"-----END CERTIFICATE-----\\n\"; WiFiClientSecure client; void drawRectDemo() { // Draw a pixel at given position for (int i = 0; i < 10; i++) { display.setPixel(i, i); display.setPixel(10 - i, i); } display.drawRect(12, 12, 20, 20); // Fill the rectangle display.fillRect(14, 14, 17, 17); // Draw a line horizontally display.drawHorizontalLine(0, 40, 20); // Draw a line horizontally display.drawVerticalLine(40, 0, 20); } void drawSpectrum(int sig, int len_sig) { display.clear(); display.drawRect(0, 0, 128, 64); display.setFont(ArialMT_Plain_10); display.setTextAlignment(TEXT_ALIGN_CENTER); display.drawString(64, 2, \"EYANTRA LAB\"); } void setup() { Serial.begin(115200); Wire.begin(5,4); // SDA, SCL display.init(); display.setFont(ArialMT_Plain_10); display.flipScreenVertically(); // Adjust to suit or remove sampling_period_us = round(1000000 * (1.0 / SAMPLING_FREQUENCY)); WiFi.mode(WIFI_STA); WiFi.begin(ssid, password); while (WiFi.status() != WL_CONNECTED) { delay(500); Serial.print(\".\"); } } void loop() { display.clear(); drawSpectrum(0,0); display.display(); for (int i = 0; i < SAMPLES; i++) { newTime = micros()-oldTime; oldTime = newTime; vReal[i] = analogRead(A0); // A conversion takes about 1uS on an ESP32 vImag[i] = 0; while (micros() < (newTime + sampling_period_us)) { /* do nothing to wait */ } } //Selection of proper window technique to obtain optimum results FFT.Windowing(vReal, SAMPLES, FFT_WIN_TYP_BLACKMAN_HARRIS, FFT_FORWARD); //Computation of FFt algorithm to obtain Real and imaginary value FFT.Compute(vReal, vImag, SAMPLES, FFT_FORWARD); FFT.ComplexToMagnitude(vReal, vImag, SAMPLES); //Convert to mag int j=0; //$- But system for proof of concept ( max0-max3) int max0=0; int max1=0; int max2=0; int max3=0; //This can either be done by calibration or by formula from ( sampling,CHUNK,desired freq) for (int i = 150 ; i < 250; i++) // for loop to iterate via all bins { if (vReal[i]>150 && i>170 &&i <180) // this is 16khz { max1 = 1; } if (vReal[i]>150 && i>185 &&i <188) // this is 17khz { max1 = 1; } if (vReal[i]>50 && i>195 &&i <205) // this is 18khz { max2 = 1; } if (vReal[i]>100 && i>210 &&i <230) // this is 19.1khz { max3 = 1; } } //To cehck for bits and print relevant user detalils ( in future it might be used with firebase if( max0==0 && max1==1 && max2==0 && max3==0 && aravinda == 0 ) { Serial.println(\"ARAVINDA HARITHSA\"); display.setFont(ArialMT_Plain_10); display.setTextAlignment(TEXT_ALIGN_CENTER); display.drawString(64, 22, \"ARAVINDA HARITHSA\"); display.drawString(64, 32, \"AUTHENTICATED...\"); display.display(); delay(1000); display.clear(); HTTPClient http; String url=\"https://script.google.com/macros/s/\"+GOOGLE_SCRIPT_ID+\"/exec?\"+ \"info1=Aravinda&info2=Intern&temp=temp\"; http.begin(url, root_ca); int httpCode = http.GET(); Serial.println(\"DONE_\"); http.end(); aravinda =1; } if(max0==0 && max1==0 && max2==1 && max3==0 && sourav == 0 ) { Serial.println(\"SOURAV JENA\"); display.setFont(ArialMT_Plain_10); display.setTextAlignment(TEXT_ALIGN_CENTER); display.drawString(64, 22, \"SOURAV JENA\"); display.drawString(64, 32, \"AUTHENTICATED...\"); display.display(); HTTPClient http; String url=\"https://script.google.com/macros/s/\"+GOOGLE_SCRIPT_ID+\"/exec?\"+ \"info1=Souvrav_Jena&info2=Mentor&temp=Permanent\"; http.begin(url, root_ca); int httpCode = http.GET(); Serial.println(httpCode); http.end(); delay(1000); sourav = 1; }","title":"Code for FFT authentication ( Near Ultrasonic)"},{"location":"Firmware/#_1","text":"","title":""},{"location":"Firmware/#_2","text":"","title":""},{"location":"Simulation/","text":"Simulation A simple circuit using eYFI Mega was simulated on e-Yantra Circuit Simulator, which is a flavor of SimulIDE circuit simulator (download here ). The firmware was loaded on the virtual eYFI Mega board and certain notes were generated, besides exhibiting characteristics such as pitch bend, scale change and volume change. Virtual COM ports were created using Virtual Serial Port Driver which were used for passing serial data from the eYFI Mega board to the DAW via simulator and Hairless MIDI<->Serial Bridge The firmware for the above configuration can be found here . Click here to get the simulation file for the above configuration.","title":"Simulation"},{"location":"Simulation/#simulation","text":"A simple circuit using eYFI Mega was simulated on e-Yantra Circuit Simulator, which is a flavor of SimulIDE circuit simulator (download here ). The firmware was loaded on the virtual eYFI Mega board and certain notes were generated, besides exhibiting characteristics such as pitch bend, scale change and volume change. Virtual COM ports were created using Virtual Serial Port Driver which were used for passing serial data from the eYFI Mega board to the DAW via simulator and Hairless MIDI<->Serial Bridge The firmware for the above configuration can be found here . Click here to get the simulation file for the above configuration.","title":"Simulation"},{"location":"Software/","text":"Python Implementation This is about python implementation of the authentication system which we discussed where we will be authenticating using the laptop based program laptop will be continuously listening from mic. Here, We have implemented multi-threading as well to increase the sampling rate and also provide accurate results. We have used mobile phone with laptop . This is screenshot of the demo system- where the audio key is being played from phone and recieved by laptop . Now lets look into more details and components . Software used Python 3.7 Pyaudio module How does it work? We will be sending useful information in inaudible spectrum range of 17-20khz and each user will be given a unique frequency to communicate with the authenticating node or device . He will send his encrypted key in serial format . We will be using Phase shift keying technique to send the data from mobile device to the authenticating node or laptop . Once the information received matches with the user credentials then the system will authenticate them and logs in their time of arrival and other details automatically . Our approach Our main logic is it will be consistently listening and once it receives sound then It takes the input data or input audio and puts into bin, bin is a container where the raw audio samples will be stored . once bin is full then will be processed for fast Fourier transform and after applying for fast Fourier transform we will be obtaining the spectrum .We will use frequency versus time plot to get the input data serial information which will be sent with PSK (phase shift keying) encoded signals .Then we will apply lot of algorithms to extract the input data , . We should provide you with the Information here in this we are using a Serial based communication where we will be sending the details in one particular frequency between user and the computer and then once the contents are received in that content are decoded using the psk module where the incoming data will be decoded. And also we will be providing our data with extra zeros so that any error or any ambient noise or Distortion might be possibly removed Decoding methodology ( Serial communication ) This is example of input signal which will be heard by the laptop's mic. This particular signal will be decoded by using various steps mentioned below to obtain the useful information out of these The FFT algorithm will be applied to get the spectrum of the input signal, here in python we will be using FFT libraries included under numpy module which will provide us with the below spectrum which is plotted using matplotlib This is the plot of input signal's FFT plotted We require only one frequency information so we will be rejecting every other values and concentrating on the value which is being sent from the phone. The below plot will show us the FFT which is plotted for one particular region of the whole spectrum and everything else will be rejected Once we get the frequency to which we are listening to then we will plot the frequency vs time we will obtain the below results as shown in the plot Once we get this plot then we will look for our desired frequency range where the signal was sent and suitable filters will be applied to remove and normalize the input serial information into more generalized processable format which can be co-related with bit values which are being sent as shown below From this again all the phase changes will be determined as we will be using PSK modulation technique to decode that data we need to know the points where the phase will change once we obtain the decoded signal this will be compared with the PSK dictionary for getting the values or characters which were being sent from the phone . As this being mission critical task we have to use multithreading where each thread will be doing it;s own allotted task and be communicating between each other ,even if we miss 0.1 seconds we would loos lot of vital information . Thus by this system we will successfully establish communication system thereby making way for secure authentication using sound signals We tested this on our laptop and we were able to successfully authenticate with audio based key. Range was also good. Pre-Generated Ultrasonic music based keys were played and those were decoded with almost 100% accuracy by our system , Here is the clip of the obtained results . Here in this pic 2 of the users where authenticated using the ultrasonic audio key which was played by phone . as this was proof of concept we just tested on to static key generation , in future versions we will work on dynamic key which will be exchanged based on encoding and decoding key based on time factor . Future scope This particular concepts are You can implement this as a two-factor authentication where Google users you send the passcode that has a dependency on your cellular area network, but this doesn't have any net dependency. We successfully tested this particular model and results are obtained were highly accurate and We have also shown popper demo videos.","title":"Python Implementation"},{"location":"Software/#python-implementation","text":"This is about python implementation of the authentication system which we discussed where we will be authenticating using the laptop based program laptop will be continuously listening from mic. Here, We have implemented multi-threading as well to increase the sampling rate and also provide accurate results. We have used mobile phone with laptop . This is screenshot of the demo system- where the audio key is being played from phone and recieved by laptop . Now lets look into more details and components .","title":"Python Implementation"},{"location":"Software/#software-used","text":"Python 3.7 Pyaudio module","title":"Software used"},{"location":"Software/#how-does-it-work","text":"We will be sending useful information in inaudible spectrum range of 17-20khz and each user will be given a unique frequency to communicate with the authenticating node or device . He will send his encrypted key in serial format . We will be using Phase shift keying technique to send the data from mobile device to the authenticating node or laptop . Once the information received matches with the user credentials then the system will authenticate them and logs in their time of arrival and other details automatically .","title":"How does it work?"},{"location":"Software/#our-approach","text":"Our main logic is it will be consistently listening and once it receives sound then It takes the input data or input audio and puts into bin, bin is a container where the raw audio samples will be stored . once bin is full then will be processed for fast Fourier transform and after applying for fast Fourier transform we will be obtaining the spectrum .We will use frequency versus time plot to get the input data serial information which will be sent with PSK (phase shift keying) encoded signals .Then we will apply lot of algorithms to extract the input data , . We should provide you with the Information here in this we are using a Serial based communication where we will be sending the details in one particular frequency between user and the computer and then once the contents are received in that content are decoded using the psk module where the incoming data will be decoded. And also we will be providing our data with extra zeros so that any error or any ambient noise or Distortion might be possibly removed","title":"Our approach"},{"location":"Software/#decoding-methodology-serial-communication","text":"This is example of input signal which will be heard by the laptop's mic. This particular signal will be decoded by using various steps mentioned below to obtain the useful information out of these The FFT algorithm will be applied to get the spectrum of the input signal, here in python we will be using FFT libraries included under numpy module which will provide us with the below spectrum which is plotted using matplotlib This is the plot of input signal's FFT plotted We require only one frequency information so we will be rejecting every other values and concentrating on the value which is being sent from the phone. The below plot will show us the FFT which is plotted for one particular region of the whole spectrum and everything else will be rejected Once we get the frequency to which we are listening to then we will plot the frequency vs time we will obtain the below results as shown in the plot Once we get this plot then we will look for our desired frequency range where the signal was sent and suitable filters will be applied to remove and normalize the input serial information into more generalized processable format which can be co-related with bit values which are being sent as shown below From this again all the phase changes will be determined as we will be using PSK modulation technique to decode that data we need to know the points where the phase will change once we obtain the decoded signal this will be compared with the PSK dictionary for getting the values or characters which were being sent from the phone . As this being mission critical task we have to use multithreading where each thread will be doing it;s own allotted task and be communicating between each other ,even if we miss 0.1 seconds we would loos lot of vital information . Thus by this system we will successfully establish communication system thereby making way for secure authentication using sound signals We tested this on our laptop and we were able to successfully authenticate with audio based key. Range was also good. Pre-Generated Ultrasonic music based keys were played and those were decoded with almost 100% accuracy by our system , Here is the clip of the obtained results . Here in this pic 2 of the users where authenticated using the ultrasonic audio key which was played by phone . as this was proof of concept we just tested on to static key generation , in future versions we will work on dynamic key which will be exchanged based on encoding and decoding key based on time factor .","title":"Decoding methodology ( Serial communication )"},{"location":"Software/#future-scope","text":"This particular concepts are You can implement this as a two-factor authentication where Google users you send the passcode that has a dependency on your cellular area network, but this doesn't have any net dependency. We successfully tested this particular model and results are obtained were highly accurate and We have also shown popper demo videos.","title":"Future scope"},{"location":"hardware/","text":"eYFi-Mega Implementation Our Model : This was the experimental setup which we constructed to show proof of concept of the Authentication system fir real world scenario. We successfully tested the accuracy,reliability and various other proposed features and came up with this model . Block diagram of our system Here a mobile phone will send the audio key and the mic will receive the signal and process the data , this has various application . Detailed working of the same will be explained below Components required: eYFi Mega Development Board Jumper wires MAX4466 High gain Microphone (20-20khz) OLED screen (0.96\") Smartphone to send Audio key Internet Connectivity (wiFi) Circuit Schematic: Working Explained The whole system works only on sound , whenever a person will approach the authenticating node then he will play the static key ( in future versions we will make that dynamic with Cryptography techniques ) this mic connected to the eYFi Mega will receive the signal and process the incoming signal to get the meaningful data from it . Then once the key is matched with already stored key in the local database then display on the OLED screen the name of the individual and also by making use of https protocol send the details to google sheet based web app which will be configured with our system . Then the login credentials such as Name,Role ,Time will be automatically updated . Methodology of Audio communication ( Parallel data transfer ) Our fundamental approach is making use of available spectral domain from 17khz to 20khz concurrently together to send the bit information . We will be for this proof of concept utilizing only 4 bits and that can be stretched as long as 25-30 bits easily. Hence we can authenticate in a fraction of a second just by comin in region of interest of the node . without any waiting time or lag Here is the brief overview of the working of our system in a block diagram Here the below image shows the potential system which can send 25-30 bits of data at once ,so making our system extremely faster and reliable . With improving of FFT algorithms,Window functions,Mic quality and lot of other factors we can substantially increase the coverage range and also the resolution of Bits .","title":"eYFi-Mega Implementation"},{"location":"hardware/#eyfi-mega-implementation","text":"","title":"eYFi-Mega Implementation"},{"location":"hardware/#our-model","text":"This was the experimental setup which we constructed to show proof of concept of the Authentication system fir real world scenario. We successfully tested the accuracy,reliability and various other proposed features and came up with this model .","title":"Our Model :"},{"location":"hardware/#block-diagram-of-our-system","text":"Here a mobile phone will send the audio key and the mic will receive the signal and process the data , this has various application . Detailed working of the same will be explained below","title":"Block diagram of our system"},{"location":"hardware/#components-required","text":"eYFi Mega Development Board Jumper wires MAX4466 High gain Microphone (20-20khz) OLED screen (0.96\") Smartphone to send Audio key Internet Connectivity (wiFi)","title":"Components required:"},{"location":"hardware/#circuit-schematic","text":"","title":"Circuit Schematic:"},{"location":"hardware/#working-explained","text":"The whole system works only on sound , whenever a person will approach the authenticating node then he will play the static key ( in future versions we will make that dynamic with Cryptography techniques ) this mic connected to the eYFi Mega will receive the signal and process the incoming signal to get the meaningful data from it . Then once the key is matched with already stored key in the local database then display on the OLED screen the name of the individual and also by making use of https protocol send the details to google sheet based web app which will be configured with our system . Then the login credentials such as Name,Role ,Time will be automatically updated .","title":"Working Explained"},{"location":"hardware/#methodology-of-audio-communication","text":"","title":"Methodology of Audio communication"},{"location":"hardware/#parallel-data-transfer","text":"Our fundamental approach is making use of available spectral domain from 17khz to 20khz concurrently together to send the bit information . We will be for this proof of concept utilizing only 4 bits and that can be stretched as long as 25-30 bits easily. Hence we can authenticate in a fraction of a second just by comin in region of interest of the node . without any waiting time or lag Here is the brief overview of the working of our system in a block diagram Here the below image shows the potential system which can send 25-30 bits of data at once ,so making our system extremely faster and reliable . With improving of FFT algorithms,Window functions,Mic quality and lot of other factors we can substantially increase the coverage range and also the resolution of Bits .","title":"( Parallel data transfer )"},{"location":"references/","text":"References : Ultrasonic authentication Systems (patent) Check here Why ultrasonic Data transmission is difficult ? Check here Near Sound Data Transfer (wiki) Check here Sending Data over sound : How and why? Check here","title":"References"},{"location":"references/#references","text":"","title":"References :"},{"location":"references/#ultrasonic-authentication-systems-patent","text":"Check here","title":"Ultrasonic authentication Systems (patent)"},{"location":"references/#why-ultrasonic-data-transmission-is-difficult","text":"Check here","title":"Why ultrasonic Data transmission is difficult ?"},{"location":"references/#near-sound-data-transfer-wiki","text":"Check here","title":"Near Sound Data Transfer (wiki)"},{"location":"references/#sending-data-over-sound-how-and-why","text":"Check here","title":"Sending Data over sound : How and why?"}]}